{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-03T08:20:11.466630Z",
     "start_time": "2024-12-03T08:20:11.452632Z"
    }
   },
   "source": [
    "# 一个 240*240 的像素，经过一个 5*5 的卷积层后，步长为1，无填充的情况下，会得到一个 236*236 的像素输出。经过10层后会得到一个 200*200 像素的图像\n",
    "# 因此，应用多层卷积时，会丢失边缘像素。由于我们通常使用小卷积核，因此对于任何单个卷积，我们可能只会丢失几个像素。 但随着我们应用许多连续卷积层，累积丢失的像素数就多了\n",
    "# 解决这个问题的简单方法即为填充,在输入图像的边界填充元素（通常填充元素是0）\n",
    "\n",
    "# 输出尺寸 = (输入尺寸 - 卷积核尺寸 + 2× 填充) / 步长 + 1\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:27:09.347044Z",
     "start_time": "2024-12-03T08:27:08.239790Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#  我们创建一个高度和宽度为3的二维卷积层，并(在所有侧边填充1个像素)。给定高度和宽度为8的输入，则输出的高度和宽度也是8\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "# 为了方便起见，我们定义了一个计算卷积层的函数。\n",
    "# 此函数初始化卷积层权重，并对输入和输出提高和缩减相应的维数\n",
    "def comp_conv2d(conv2d, X):\n",
    "    # 这里的（1，1）表示批量大小和通道数都是1\n",
    "    X = X.reshape((1, 1) + X.shape)\n",
    "    Y = conv2d(X)\n",
    "    # 省略前两个维度：批量大小和通道\n",
    "    return Y.reshape(Y.shape[2:])\n",
    "\n",
    "# 请注意，这里每边都填充了1行或1列，因此总共添加了2行或2列\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1)\n",
    "X = torch.rand(size=(8, 8))\n",
    "comp_conv2d(conv2d, X).shape"
   ],
   "id": "ac8cc1cf2fd7fec7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:27:36.192395Z",
     "start_time": "2024-12-03T08:27:36.178059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 当卷积核的高度和宽度不同时，我们可以[填充不同的高度和宽度]，使输出和输入具有相同的高度和宽度。在如下示例中，我们使用高度为5，宽度为3的卷积核，高度和宽度两边的填充分别为2和1。\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=(5, 3), padding=(2, 1))\n",
    "comp_conv2d(conv2d, X).shape"
   ],
   "id": "4c381b69e73e33c1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:29:07.251968Z",
     "start_time": "2024-12-03T08:29:07.230696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 在前面的例子中，我们默认每次滑动一个元素。 但是，有时候为了高效计算或是缩减采样次数，卷积窗口可以跳过中间位置，每次滑动多个元素。\n",
    "# 我们将每次滑动元素的数量称为步幅（stride）\n",
    "# 我们[将高度和宽度的步幅设置为2]，从而将输入的高度和宽度减半。\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1, stride=2)\n",
    "comp_conv2d(conv2d, X).shape"
   ],
   "id": "71e8d2cadc125379",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:29:32.137822Z",
     "start_time": "2024-12-03T08:29:32.117396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "conv2d = nn.Conv2d(1, 1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))\n",
    "comp_conv2d(conv2d, X).shape\n",
    "\n"
   ],
   "id": "6d7084902c09728e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
